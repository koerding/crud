\section{Discussion}

As noted in the introduction, three common uses of correlation are: large effects that stand out far beyond the background dependence scale, prediction without causal claims, and small-effect causal claims that rely on adjusted associations standing out from background dependence. Our results target this third use: when reported adjusted associations are comparable to the crud scale, causal interpretation is fragile without additional design leverage, even if classical $p$-values are tiny. The crud-aware calibration we propose provides a minimal standard for deciding when a small association is worth interpreting at all.

There are effects so large that pervasive background dependence is irrelevant. Smoking and lung cancer show extremely large associations; pooled multiple-adjusted relative risks are about 7 in large cohort meta-analyses, which easily clear any reasonable background dependence scale \citep{okeeffe2018}. A second concrete example from a different domain is the HEXACO literature: Dark Triad traits are strongly negatively correlated with Honesty-Humility ($r$s $= -0.72, -0.57, -0.53$), which is far into the tail of any reasonable background correlation distribution \citep{lee2005}. By contrast, across the modern domains we study, typical correlations are much weaker than these textbook examples, and many reported small effects do not clear the crud scale after generic adjustment. As a positive control, within-facet HEXACO item pairs clear the crud scale easily (best pair $>$99.99th percentile), showing the calibration identifies genuinely strong associations when they exist.

\paragraph{Scope and leverage.} In some cases, prior knowledge or design-based leverage effectively isolates variables from background dependence. Randomized treatments, discontinuities, policy changes, and valid instruments provide leverage that is orthogonal to generic correlation structure. Similarly, informed selection of which pairs to examine---guided by prior biological knowledge, mechanistic models, or pathway databases---constitutes a structural prior that effectively narrows the background distribution; our impossibility result applies to the association statistic itself, not to the prior that selected the pair. Our results do not argue against such approaches; they target association-only workflows that interpret small adjusted pairwise correlations as evidence for direct causal structure in the absence of additional leverage. In our nine datasets, most adjusted correlations that would be called ``significant'' under iid testing fall near the center of the crud distribution rather than in its tails (Figure~\ref{fig:corr-dist}; Table~\ref{tab:crud-scale}), reinforcing the practical need for crud-aware calibration.

These observations also constrain automated causal reasoning: no amount of computational power can extract a signal that is not present in the data, so the crud scale bounds what any association-based system can learn, regardless of its sophistication (systems that combine data with mechanistic priors or interventions are not subject to this bound).

One striking upshot is the homogeneity of these properties across very different domains. The prevalence of broad spectra and slow shrinkage of the crud scale suggests that many modern datasets share a common statistical obstacle, and that calibration against background dependence is a cross-domain issue rather than a niche pathology.

\subsection{Limitations}

All results in this paper concern linear dependence: correlations, linear PC adjustment, and eigenvalue spectra of the covariance matrix. Many real-world domains exhibit substantial nonlinear dependence---gene regulatory networks involve thresholding and saturation, neural population codes are nonlinear functions of stimuli, and epidemiological dose-response curves are rarely linear. In such settings, the linear crud scale $\sigma_K$ is a lower bound on the true background dependence: nonlinear shared variation that is invisible to PCA can still generate spurious pairwise associations in nonlinear statistics (e.g., mutual information, kernel-based dependence measures). This means our calibration is conservative with respect to nonlinear confounding---the actual background may be worse than what the linear analysis reveals.

Our empirical results are based on nine datasets chosen for size and availability, and the quantitative crud scale will vary across domains and preprocessing choices. We use PC regression as a deliberately generic adjustment, not as a claim of causal identification. In high-dimensional settings, generic adjustment itself can be a source of uncertainty: when $p$ is not small relative to $n$, estimating dominant directions and forming residualized associations can introduce nontrivial estimation error and instability, even when raw correlations are estimated precisely. This is most acute in datasets such as GTEx RNA-seq where $p \gg n$; in these settings, estimation of the eigenvalue tail and thus $\sigma_K$ is noisier, and sensitivity checks are reported in Appendix~\ref{app:alt-adjust}. These caveats do not change the main point, but they limit the precision of any crude calibration that ignores adjustment uncertainty.

